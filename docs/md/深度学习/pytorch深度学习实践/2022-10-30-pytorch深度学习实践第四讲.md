# 反向传播
## 问题提出
在前篇的线性模型中
$$
\widehat y = \omega x
$$
如果以神经网络的视角代入来看，则$x$为输入层，即input层，$\omega$为权重，$\widehat y$为输出层。在神经网络中，通常将$\omega$以及$*$计算操作的部分合并看做一个神经元（层）。而神经网络的训练过程即为更新$\omega$的过程，其更新的情况依赖于$\frac{\partial loss}{\partial \omega}$,而并非$\frac{\partial \widehat y}{\partial \omega}$.
![神经网络视角下的线性模型](https://cdn.acwing.com/media/article/image/2022/11/24/192601_ddef02d06c-py14.png) 
然而，对于复杂模型而言求解过程就复杂很多。在图示的神经网络中，每个结点为一个神经元，结点之间的连线为权重。记各符合表示如表所示

符号/含义

$x_i$
输入层的第i个结点

$h_{ij}$
第i层隐含层的第j个结点

$o_i$
输出层的第i个结点

$\omega_{x1}^{mn}$
输入层的第m个结点与隐含层的第n个结点之间的权重

$\omega_{ij}^{mn}$
隐含层第i层的第m个结点与第j层的第n个结点之间的权重

$\omega_{ko}^{mn}$
隐含层最后一层（第k层）的第m个结点与输出层第n个结点之间的权重
![含有四个隐含层的神经网络模型](https://cdn.acwing.com/media/article/image/2022/11/24/192601_34973e296c-py15.png) 
由图上可知，输入层与隐含层第一层之间就有$5*6=30$个权重，隐含层的第一层与第二层之间又有$6*7=42$个权重，以此类推，上图中共有$30+42+49+42+30=193$个权重需要计算，传统得列表达式的方式是无法完成的。
##计算图中的神经网络
在计算图中，绿色的模块为计算模块，可以在计算过程中求导。MM为矩阵乘法，ADD为加法。
![py16.png](https://cdn.acwing.com/media/article/image/2022/11/24/192601_5af879b96c-py16.png) 
而上图左式中，可以化简得到如下公式
$$
\widehat y = W_2(W_1X+b_1)+b_2=W_2W_1X+(W_2b_1+b_2)=WX+b
$$
也就是说，在这个结构下单纯的增加层数，并不能增加神经网络的复杂程度，因为最后都可以化简为一个单一的神经网络
![神经网络的无效复杂](https://cdn.acwing.com/media/article/image/2022/11/24/192601_a171262a6c-py17.png)
### 改进
在每层网络结构中，增加一个非线性的变换函数（激活函数）
![增加激活函数以后的神经网络](https://cdn.acwing.com/media/article/image/2022/11/24/192601_c9a68f1a6c-py18.png)  
## 反向传播过程
### 前馈计算
在某一神经元处，输入的$x$与$\omega$经过函数$f(x,\omega)$的计算,可以获得输出值$z$，并继续向前以得到损失值loss.
在向前计算的过程中，在$f(x,\omega)$的计算模块中会计算导数$\frac{\partial z}{\partial x}$以及$\frac{\partial z}{\partial \omega}$,并将其保存下来（在pytorch中，这样的值保存在变量$x$以及$\omega$中）。
![前馈计算过程](https://cdn.acwing.com/media/article/image/2022/11/24/192601_fb0b24fc6c-py19.png) 
### 反向传播
由于求导的链式法则,求得loss以后，前面的神经元会将$\frac{\partial loss}{\partial z}$的值反向传播给原先的神经元，在计算单元$f(x,\omega)$中,将得到的$\frac{\partial loss}{\partial x}$与之前存储的导数相乘，即可得到损失值对于权重以及输入层的导数，即$\frac{\partial loss}{\partial x}$,以及$\frac{\partial loss}{\partial \omega}$.基于该梯度才进行权重的调整。
![反向传播过程](https://cdn.acwing.com/media/article/image/2022/11/24/192601_2c94e0556c-py20.png)
# Pytorch中的前馈与反馈
利用pytorch进行深度学习，最主要的是==构建计算图==
## Tensor（张量）
Tensor中重要的两个成员，data用于保存权重本身的值$\omega$,grad用于保存损失函数对权重的导数$\frac{\partial loss}{\partial \omega}$，grad本身也是个张量。对张量进行的计算操作，都是建立计算图的过程。
![张量Tensor](https://cdn.acwing.com/media/article/image/2022/11/24/192601_5df878b86c-py21.png)  
## 代码说明：

1、w是Tensor(张量类型)，Tensor中包含data和grad，data和grad也是Tensor。grad初始为None，调用l.backward()方法后w.grad为Tensor，故更新w.data时需使用w.grad.data。如果w需要计算梯度，那构建的计算图中，跟w相关的tensor都默认需要计算梯度。

刘老师视频中a = torch.Tensor([1.0]) 本文中更改为 a = torch.tensor([1.0])。两种方法都可以，个人习惯第二种。
```

import torch
a = torch.tensor([1.0])
a.requires_grad = True # 或者 a.requires_grad_()
print(a)
print(a.data)
print(a.type())             # a的类型是tensor
print(a.data.type())        # a.data的类型是tensor
print(a.grad)
print(type(a.grad))

```
结果为：
![结果][1]
2、w是Tensor， forward函数的返回值也是Tensor，loss函数的返回值也是Tensor

3、本算法中反向传播主要体现在，l.backward()。调用该方法后w.grad由None更新为Tensor类型，且w.grad.data的值用于后续w.data的更新。

     l.backward()会把计算图中所有需要梯度(grad)的地方都会求出来，然后把梯度都存在对应的待求的参数中，最终计算图被释放。

     取tensor中的data是不会构建计算图的。
```
import torch
x_data = [1.0, 2.0, 3.0]
y_data = [2.0, 4.0, 6.0]
 
w = torch.tensor([1.0]) # w的初值为1.0
w.requires_grad = True # 需要计算梯度
 
def forward(x):
    return x*w  # w是一个Tensor
 
 
def loss(x, y):
    y_pred = forward(x)
    return (y_pred - y)**2
 
print("predict (before training)", 4, forward(4).item())
 
for epoch in range(100):
    for x, y in zip(x_data, y_data):
        l =loss(x,y) # l是一个张量，tensor主要是在建立计算图 forward, compute the loss
        l.backward() #  backward,compute grad for Tensor whose requires_grad set to True
        print('\tgrad:', x, y, w.grad.item())
        w.data = w.data - 0.01 * w.grad.data   # 权重更新时，注意grad也是一个tensor
 
        w.grad.data.zero_() # after update, remember set the grad to zero
 
    print('progress:', epoch, l.item()) # 取出loss使用l.item，不要直接使用l（l是tensor会构建计算图）
 
print("predict (after training)", 4, forward(4).item())


```


  [1]: https://cdn.acwing.com/media/article/image/2022/10/30/192601_104d99e258-%E7%BB%93%E6%9E%9C.png