# PyTorch深度学习实践——线性模型
## 进行深度学习时的准备步骤

 - 准备数据集
 - 选择模型
 - 模型训练
 - 进行推理预测
## 问题引入
![py1.png](https://cdn.acwing.com/media/article/image/2022/11/22/192601_2e1922a06a-py1.png) 
## 问题分析
### 基本流程
数据集需要交付给算法模型进行训练，利用所训练的模型，在获得新的数据时可以获得相应的输出。（监督学习）
### 训练集与测试集
在上述问题中，前三行里对应的每个$x$,有其对应的输出$y$，因此前三行可以作为训练集(Training Set)来进行训练。
![py2.png](https://cdn.acwing.com/media/article/image/2022/11/22/192601_2aa76a966a-py2.png) 
### 验证集
测试集的标准答案一般是不知道的，因此训练之后的模型对具体问题的适配程度并不可知。如果利用训练集来进行验证，会出现“自己考自己”这样的情况，容易过拟合。为了提升泛化能力，将训练集分成训练集和验证集（Validation Set）
## 模型设计
线性模型的基本模型y=wx+b，其中的w和b是模型中的参数，训练模型的过程即为确定模型中参数的过程
在本模型中设置成y=wx，对于不同的w有不同的线性模型及图像与之对应。
![py3.png](https://cdn.acwing.com/media/article/image/2022/11/22/192601_f7a813c96a-py3.png) 
## 模型训练过程
在模型训练中会先随机取得一个值，继而计算其和标准量之间的偏移量，从而判断当前模型是否符合预期。
记实际值为y(x),模型对应的预测值为y_hat(x)，则其中的偏移量为|y_hat(x)-y(x)|，以此来代表模型估计值对原值的误差。
通常，该公式定义为Training Loss (Error)
loss=(y_hat-y)²=（wx-y)²
原题目中的几种$\omega$所对应的Loss如下
![py4.png](https://cdn.acwing.com/media/article/image/2022/11/22/192601_948346826a-py4.png) 
其中的每行为$w$不同时的单个样本的损失，最后一行为平均损失。
对于单个样本，有loss可用于指代样本误差。对于所有样本，可同理用==Mean Square Error （MSE）==来指代整体样本的平均平方误差（均方差cost）
![py5.png](https://cdn.acwing.com/media/article/image/2022/11/22/192601_badfa5c86a-py5.png) 
## 代码说明
1、函数forward()中，有一个变量w。这个变量最终的值是从for循环中传入的。
2、for循环中，使用了np.arange。若对numpy不太熟悉，传送门Numpy数据计算从入门到实战
3、python中zip()函数的用法

```
import numpy as np
import matplotlib.pyplot as plt
 
x_data = [1.0, 2.0, 3.0]
y_data = [2.0, 4.0, 6.0]
 
 
def forward(x):
    return x*w
 
 
def loss(x, y):
    y_pred = forward(x)
    return (y_pred - y)**2
 
 
# 穷举法
w_list = []
mse_list = []
for w in np.arange(0.0, 4.1, 0.1):
    print("w=", w)
    l_sum = 0
    for x_val, y_val in zip(x_data, y_data):
        y_pred_val = forward(x_val)
        loss_val = loss(x_val, y_val)
        l_sum += loss_val
        print('\t', x_val, y_val, y_pred_val, loss_val)
    print('MSE=', l_sum/3)
    w_list.append(w)
    mse_list.append(l_sum/3)
    
plt.plot(w_list,mse_list)
plt.ylabel('Loss')
plt.xlabel('w')
plt.show()    


```